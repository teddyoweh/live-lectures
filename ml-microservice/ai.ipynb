{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import io\n",
    "import math\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "import math\n",
    "\n",
    "# Function to split audio into 10-minute segments\n",
    "def split_audio(audio_file_path, segment_length=5 * 60 * 500):  # 10 minutes in milliseconds\n",
    "    audio = AudioSegment.from_mp3(audio_file_path)\n",
    "    segment_count = math.ceil(len(audio) / segment_length)\n",
    "\n",
    "    segments = []\n",
    "    for i in range(segment_count):\n",
    "        start_time = i * segment_length\n",
    "        end_time = min((i + 1) * segment_length, len(audio))\n",
    "        segment = audio[start_time:end_time]\n",
    "        segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Split the audio file into 10-minute segments\n",
    "audio_segments = split_audio(\"output.mp3\")\n",
    "\n",
    "# Convert each segment to WAV format and transcribe\n",
    "transcriptions = []\n",
    "for i, segment in enumerate(audio_segments, start=1):\n",
    "    # Convert to WAV format\n",
    "    wav_segment = segment.export(format=\"wav\")\n",
    "\n",
    "    audio_segment_io = io.BytesIO()\n",
    "    wav_segment.seek(0)\n",
    "    audio_segment_io.write(wav_segment.read())\n",
    "    audio_segment_io.seek(0)\n",
    "\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_segment_io\n",
    "    )\n",
    "\n",
    "    print(f\"Transcription for segment {i}: {transcription.text}\")\n",
    "    transcriptions.append(transcription.text)\n",
    "\n",
    "# Merge all transcriptions into one variable\n",
    "merged_transcription = \" \".join(transcriptions)\n",
    "print(\"Merged Transcription:\", merged_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_frames(video_path, output_path, frame_interval=5):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frames = []\n",
    "\n",
    "    while success:\n",
    "        if count % (frame_interval * int(vidcap.get(cv2.CAP_PROP_FPS))) == 0:\n",
    "            timestamp = count / vidcap.get(cv2.CAP_PROP_FPS)\n",
    "            frames.append((image, timestamp))  # appending both image and timestamp\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    return frames\n",
    "\n",
    "def create_grid(frames, grid_size):\n",
    "    grid = None\n",
    "    rows, cols = grid_size\n",
    "    frame_height, frame_width, _ = frames[0][0].shape\n",
    "\n",
    "    for r in range(rows):\n",
    "        row_images = []\n",
    "        row_timestamps = []\n",
    "        for c in range(cols):\n",
    "            index = r * cols + c\n",
    "            if index < len(frames):\n",
    "                row_images.append(frames[index][0])\n",
    "                row_timestamps.append(frames[index][1])\n",
    "            else:\n",
    "                # Append a blank image and timestamp if there are no more frames\n",
    "                row_images.append(cv2.imread('blank_image.jpg')) # Provide path to your blank image\n",
    "                row_timestamps.append(0.0)\n",
    "\n",
    "        row_concatenated = cv2.hconcat(row_images)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        for i, timestamp in enumerate(row_timestamps):\n",
    "            minutes = int(timestamp) // 60\n",
    "            seconds = int(timestamp) % 60\n",
    "            timestamp_str = f'{minutes:02d}:{seconds:02d}'\n",
    "            cv2.putText(row_concatenated, timestamp_str, (i * frame_width + 10, frame_height - 10), font, 5, (255, 255, 255), 7, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        if grid is None:\n",
    "            grid = row_concatenated\n",
    "        else:\n",
    "            grid = cv2.vconcat([grid, row_concatenated])\n",
    "\n",
    "    return grid\n",
    "\n",
    "def save_grid(grid, output_path, quality=40):\n",
    "    cv2.imwrite(output_path, grid, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"state.mp4\"\n",
    "    output_path = \"./grid2.jpg\"\n",
    "    frame_interval = 5  # 5 seconds\n",
    "    grid_size = (6,6)  # 4 rows x 5 columns\n",
    "\n",
    "    frames = extract_frames(video_path, output_path, frame_interval)\n",
    "    grid = create_grid(frames, grid_size)\n",
    "    save_grid(grid, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "def encode_image(image):\n",
    "    _, buffer = cv2.imencode('.jpg', image)\n",
    "    return base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "def extract_frames(video_path, frame_interval=5):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frames = []\n",
    "\n",
    "    while success:\n",
    "        if count % (frame_interval * int(vidcap.get(cv2.CAP_PROP_FPS))) == 0:\n",
    "            timestamp = count / vidcap.get(cv2.CAP_PROP_FPS)\n",
    "            frames.append((image, timestamp))  # appending both image and timestamp\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    return frames\n",
    "\n",
    "def create_grid(frames, grid_size):\n",
    "    grid = []\n",
    "    rows, cols = grid_size\n",
    "    frame_height, frame_width, _ = frames[0][0].shape\n",
    "\n",
    "    # Determine the target height for resizing\n",
    "    target_height = max(frame_height for frame, _ in frames)\n",
    "\n",
    "    for r in range(rows):\n",
    "        row_images = []\n",
    "        row_timestamps = []\n",
    "        for c in range(cols):\n",
    "            index = r * cols + c\n",
    "            if index < len(frames):\n",
    "                frame, timestamp = frames[index]\n",
    "                # Resize the frame to the target height\n",
    "                frame_resized = cv2.resize(frame, (int(frame_width * target_height / frame_height), target_height))\n",
    "                row_images.append(encode_image(frame_resized))\n",
    "                row_timestamps.append(timestamp)\n",
    "            else:\n",
    "                row_images.append(None)\n",
    "                row_timestamps.append(0.0)\n",
    "\n",
    "        grid.append(row_images)\n",
    "\n",
    "\n",
    " \n",
    "    return np.array(grid).flatten()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"w.MOV\"\n",
    "    frame_interval = 6  # 5 seconds\n",
    "    grid_size = (6, 6)  # 6 rows x 6 columns\n",
    "\n",
    "    frames = extract_frames(video_path, frame_interval)\n",
    "    grid = create_grid(frames, grid_size)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "content = [\n",
    "    {\"type\": \"text\", \"text\": \"for each image in the grid, get what the image is about return it in a json format ensure you get all 36, {'':''}  \"}]+[{\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"} for base64_image in grid]\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/36\n",
      "2/36\n",
      "3/36\n",
      "4/36\n",
      "5/36\n",
      "6/36\n",
      "7/36\n",
      "8/36\n",
      "9/36\n",
      "10/36\n",
      "11/36\n",
      "12/36\n",
      "13/36\n",
      "14/36\n",
      "15/36\n",
      "16/36\n",
      "17/36\n",
      "18/36\n",
      "19/36\n",
      "20/36\n",
      "21/36\n",
      "22/36\n",
      "23/36\n",
      "24/36\n",
      "25/36\n",
      "26/36\n",
      "27/36\n",
      "28/36\n",
      "29/36\n",
      "30/36\n",
      "31/36\n",
      "32/36\n",
      "33/36\n",
      "34/36\n",
      "35/36\n",
      "36/36\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "responses = []\n",
    "for base64_image in grid:\n",
    " i+=1   \n",
    " response = client.chat.completions.create(\n",
    "  model=\"gpt-4-vision-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\":  [\n",
    "          {\"type\": \"text\", \"text\": \"for each image in the grid, get what the image is about return it in a json format ensure you get all 36, {'':''}  \"},\n",
    "          {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"} \n",
    "        ] \n",
    "    }\n",
    "  ],\n",
    "  max_tokens=1000,\n",
    ")\n",
    " responses.append(response)\n",
    " print(f\"{i}/{len(grid)}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\n\u001b[0;31m    eval(response.choices[0].message.content.strip('`').strip('json').strip('\\n'))\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    I'm sorry, but I can't provide a description for these images as there seems to be a technical issue preventing me from accessing the content of the images. If you can provide descriptions or context for each image, I'd be happy to help format this information into JSON for you.\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eval(response.choices[0].message.content.strip('`').strip('json').strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='chatcmpl-9AxTkJVbFuhyj4WzinpxIjxDoZBnN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sorry, but I can't provide information about the content of images if you don't upload any images for me to analyze. If you upload the grid of images or any other image, I'd be happy to help you with your request.\", role='assistant', function_call=None, tool_calls=None))], created=1712398944, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=48, prompt_tokens=1142, total_tokens=1190)),\n",
       " ChatCompletion(id='chatcmpl-9AxTpuNwUCgiOEoh0uJRRGnc5n4Gb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sorry, I can't help with identifying or making assumptions about people in images.\", role='assistant', function_call=None, tool_calls=None))], created=1712398949, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=1142, total_tokens=1158)),\n",
       " ChatCompletion(id='chatcmpl-9AxTuHgCrntTZ0jVNg1XBRPE6eLx2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it seems there has been a misunderstanding. There is only one image provided here, not a grid of 36 images. Based on the single image you\\'ve shared, here is a JSON formatted description:\\n\\n```json\\n{\\n  \"description\": \"Two individuals dressed in what appears to be live-action role-playing (LARP) costumes resembling fantasy warrior outfits, with one of them looking at a smartphone.\"\\n}\\n```\\n\\nIf you meant to provide a grid of images or have multiple images for analysis, please provide all the necessary images.', role='assistant', function_call=None, tool_calls=None))], created=1712398954, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=111, prompt_tokens=1142, total_tokens=1253)),\n",
       " ChatCompletion(id='chatcmpl-9AxU0HZG8sdOg1lUbf2UKx3ha0KVB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for any misunderstanding, but there is only one image provided here, not a grid of 36 images. Based on the single image you have provided, I can give you information in JSON format about this specific picture:\\n\\n```json\\n{\\n  \"image_description\": \"Two individuals dressed in fantasy-themed costumes resembling a warrior and a knight are standing next to a car that appears to have been damaged by a fallen tree branch. The person on the left is wearing dark armor with blue fabric and is looking at a smartphone. The person on the right is wearing a golden helmet, red and gold armor with a yellow fabric draped over them. There is a sense of juxtaposition between the modern device and the historical or fantasy setting implied by their costumes.\"\\n}\\n```\\n\\nIf you have a grid of 36 images and wish to receive a JSON description for each, you would need to provide all of the images.', role='assistant', function_call=None, tool_calls=None))], created=1712398960, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=183, prompt_tokens=1142, total_tokens=1325)),\n",
       " ChatCompletion(id='chatcmpl-9AxUDWCLreLn0P4uIRu8VTD6EQIue', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it seems there has been a misunderstanding. There is only one image provided here. Therefore, I can only analyze the content of the single image you\\'ve shared with me. If you have a grid of images, you will need to provide the full grid or describe them separately for me to be able to assist you with your request.\\n\\nBased on the image you\\'ve uploaded:\\n\\n```json\\n{\\n  \"image_1\": \"A person in what appears to be a police or security uniform, looking upwards with a concerned or attentive expression, in an outdoor setting\"\\n}\\n```\\n\\nIf you have more images or a grid as mentioned, please provide them so I can analyze each one and return the information in the JSON format as you\\'ve requested.', role='assistant', function_call=None, tool_calls=None))], created=1712398973, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=153, prompt_tokens=1142, total_tokens=1295)),\n",
       " ChatCompletion(id='chatcmpl-9AxUKOGQ8Rw5wkpTR4lZ94lKAqDax', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it seems there is a misunderstanding. There is only one image provided here. Therefore, I cannot return information about a grid of 36 images. However, I can describe the single image you have shared.\\n\\nBased on the single image provided, here\\'s a description in JSON format:\\n\\n```json\\n{\\n  \"image_1\": \"Two individuals dressed in fantasy medieval-like costumes, possibly portraying characters from a story or a play. The person on the left is wearing a blue and black outfit with a circular emblem and is equipped with a sword. They are looking to their side at the other person, who is dressed in a yellow and red outfit with a cape and a golden helmet, smiling and also holding a sword. They seem to be in a lighthearted interaction in a forested outdoor setting.\"\\n}\\n```\\n\\nIf there are indeed 36 different images that need to be described, please provide all the images or clarify how they can be accessed.', role='assistant', function_call=None, tool_calls=None))], created=1712398980, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=198, prompt_tokens=1142, total_tokens=1340)),\n",
       " ChatCompletion(id='chatcmpl-9AxUYIKjqWZt3psVNMdVLLgRVd1Si', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but I can only see one image in your prompt, which is a logo of State Farm, an insurance company. If there is supposed to be a grid of images, it was not provided correctly. Please provide the full set of images, and I will help you analyze each one. Here is the JSON format for the single image I can currently see:\\n\\n```json\\n{\\n  \"image1\": \"State Farm insurance company logo\"\\n}\\n```\\n\\nFor the full grid of 36 images, you would typically expect an extended JSON object with keys like \"image1\", \"image2\", ..., \"image36\", each paired with a description of the particular image. If you provide the additional images, I can complete the JSON object accordingly.', role='assistant', function_call=None, tool_calls=None))], created=1712398994, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=152, prompt_tokens=1142, total_tokens=1294)),\n",
       " ChatCompletion(id='chatcmpl-9AxUk7JVCTHBFAie4OWAtK5I9ggtP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sorry, but it seems there's a misunderstanding. The image provided does not contain a grid of 36 images. It is a single image showing a car's dashboard with a steering wheel, a digital speedometer, and a device with a red glowing eye, which could be a reference to an artificial intelligence or a camera.\\n\\nIf you have a grid of 36 images, please provide the full grid or send them individually, and I'll help identify what each image is about.\", role='assistant', function_call=None, tool_calls=None))], created=1712399006, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=96, prompt_tokens=1142, total_tokens=1238)),\n",
       " ChatCompletion(id='chatcmpl-9AxUqK2sD27kdzZ36lvdsOIikYxw4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a confusion because the image you\\'ve provided is not a grid of 36 images; it\\'s a single image of two people standing in a kitchen. Therefore, I can only provide the description for this one image. Here is the information in JSON format:\\n\\n```json\\n{\\n  \"image_description\": \"Two people standing in a modern kitchen. The person on the left is holding an orange coffee cup and seems to be talking or looking forward, while the person on the right is holding a blue cup, possibly stirring tea or coffee. The kitchen is white-themed with a contemporary design. There is a microwave, a kitchen range hood, and various kitchenwares and plants on the counters. A window with blinds partially open shows daylight coming through, suggesting it\\'s daytime.\"\\n}\\n```\\n\\nIf there is supposed to be a grid or you have additional images, please ensure to provide each image or correct the grid, so I could process them accordingly.', role='assistant', function_call=None, tool_calls=None))], created=1712399012, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=197, prompt_tokens=1142, total_tokens=1339)),\n",
       " ChatCompletion(id='chatcmpl-9AxUxn9wEr3QfPFbFN5FYmJcEWX9F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for the confusion, but based on the image provided, there is only a single image displayed instead of a grid of multiple images. The image depicts a scene of a woman sitting at a desk in an office environment talking on the phone. The office is adorned with the branding of \"State Farm,\" indicating that this is a State Farm insurance office. The text on the screen indicates she is speaking about home and auto insurance. There are no grid of images to provide details about in JSON format.\\n\\nIf by \"get what the image is about\" you mean to summarize this single image, then here is the information in JSON format:\\n\\n```json\\n{\\n  \"1\": \"A State Farm insurance agent is in her office talking on the phone about home and auto insurance.\"\\n}\\n```\\n\\nPlease provide the correct number of images or a different set if you need information on multiple images formatted in JSON.', role='assistant', function_call=None, tool_calls=None))], created=1712399019, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=181, prompt_tokens=1142, total_tokens=1323)),\n",
       " ChatCompletion(id='chatcmpl-9AxV2BO3jH3j6uQOY5gfmU7hulAaw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for any confusion, but there is only one image provided in your message. The image depicts a close-up view of a red round object, possibly a smart speaker or device, in the foreground with a blurred background that includes a framed photograph of two people and a green object which might be a vase or decorative item.\\n\\nHere is the information in JSON format as requested:\\n\\n```json\\n{\\n  \"image_1\": \"A close-up of a red round device, possibly a smart speaker, with a blurred background showing a framed photograph of two people and a green decorative item.\"\\n}\\n```\\n\\nIf there is supposed to be a grid of images, it was not provided in your message. Please provide the grid or the other images you would like me to describe, and I would be happy to assist you further.', role='assistant', function_call=None, tool_calls=None))], created=1712399024, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=165, prompt_tokens=1142, total_tokens=1307)),\n",
       " ChatCompletion(id='chatcmpl-9AxV9ojyfYwgsVBF1l6EUPiTVPiUT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It appears that you have provided a single image rather than a grid of images. From the provided image, I can only generate a JSON object representing the content of this single image. Here\\'s the JSON representation:\\n\\n```json\\n{\\n  \"image1\": \"State Farm insurance company advertisement\"\\n}\\n```\\n\\nIf you have a grid of 36 images you want to analyze, please provide all the images, and I will describe each one in a similar JSON format.', role='assistant', function_call=None, tool_calls=None))], created=1712399031, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=93, prompt_tokens=1142, total_tokens=1235)),\n",
       " ChatCompletion(id='chatcmpl-9AxVEX3ipttdvTveqjuz7dMaAHRk1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it appears there has been a misunderstanding. The image you provided is a single image, there\\'s no grid of images present that I can analyze. The image shows a man in a red basketball jersey standing in a room that appears to have a shelf with shoes in the background, suggesting a setting possibly related to sports or athletic endeavors.\\n\\nHowever, if you have a grid of images, you can share them, and I\\'d be pleased to describe each one as per your request. If you’re asking for a JSON format response for this particular image, it might look like this:\\n\\n```json\\n{\\n  \"image_description\": \"A man in a red basketball jersey standing in a room with a shoe rack in the background.\"\\n}\\n```\\n\\nPlease provide the grid of images you are referring to, and I will help accordingly.', role='assistant', function_call=None, tool_calls=None))], created=1712399036, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=169, prompt_tokens=1142, total_tokens=1311)),\n",
       " ChatCompletion(id='chatcmpl-9AxVKNlCWJ0jiYhNTyFTMsIFe0ssU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sorry, but there aren\\'t multiple images in a grid as you described. The image you provided is a single image which appears to be a screenshot from a commercial featuring two men— one dressed in a basketball jersey and holding dumbbells, and the other wearing a red T-shirt, probably engaged in a conversation.\\n\\nAs requested, I will express the information about this single image in JSON format below:\\n\\n```json\\n{\\n  \"image_1\": \"A commercial featuring two men in a home gym, one in a basketball jersey and holding dumbbells, the other in a red T-shirt, having a conversation.\"\\n}\\n```\\n\\nPlease provide the set of images or clarify your request if you are looking for a specific set of multiple images.', role='assistant', function_call=None, tool_calls=None))], created=1712399042, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=149, prompt_tokens=1142, total_tokens=1291)),\n",
       " ChatCompletion(id='chatcmpl-9AxVQT3eGiBsK907wIHoZArv54h8W', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a misunderstanding. The image you\\'ve provided is just one image. I do not have access to a grid of 36 images. From the image provided, however, I can offer a JSON-formatted description of the single image shown:\\n\\n```json\\n{\\n  \"1\": \"Image of a man in a home gym with workout equipment, standing confidently with text overlay that reads \\'THE NEW CHRIS PAUL WORKOUT SHOW\\'. There is a recording overlay indicating that this scene is being recorded, potentially for a workout video or show.\"\\n}\\n```\\n\\nIf you have a grid of images you would like to be described, please provide the full image or set of images, and I would be happy to assist you.', role='assistant', function_call=None, tool_calls=None))], created=1712399048, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=152, prompt_tokens=1142, total_tokens=1294)),\n",
       " ChatCompletion(id='chatcmpl-9AxVWU9KX4ZKNWza0lpkngKp9zf1L', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there appears to be a misunderstanding. The image provided is a single image and not a grid of multiple images. Based on the visual provided, I can offer you a description for this one image in JSON format:\\n\\n```json\\n{\\n  \"description\": \"A person is doing a workout in a well-equipped home gym featuring various gym equipment like dumbbells, weight benches, an exercise ball, stationary bicycles, and weight machines. There is also a video camera set up, possibly recording the workout session.\"\\n}\\n```\\n\\nIf you have a grid of images or multiple images that you need descriptions for, please provide those images for analysis.', role='assistant', function_call=None, tool_calls=None))], created=1712399054, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=132, prompt_tokens=1142, total_tokens=1274)),\n",
       " ChatCompletion(id='chatcmpl-9AxVbzCDotsERCqEdb3BkWKXtLTJz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it appears there is only one image provided here rather than a grid of images. The image shows two individuals seemingly having a conversation in a gym environment. One person is wearing a red basketball jersey with the text \"THE NEW CHRIS PAUL\" and the other is wearing a plain red t-shirt with a logo on it. \\n\\nBased on the information provided, I can only offer a JSON representation for this single image:\\n\\n```json\\n{\\n  \"image1\": \"two individuals talking in a gym, one wearing a basketball jersey and the other a red t-shirt\"\\n}\\n```\\n\\nIf there is indeed a grid of 36 images that you\\'d like to have described in JSON format, please provide all of the images so I can assist you accurately.', role='assistant', function_call=None, tool_calls=None))], created=1712399059, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=156, prompt_tokens=1142, total_tokens=1298)),\n",
       " ChatCompletion(id='chatcmpl-9AxVjVEA0m6jbYsU4DsIK5LrioozU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for the confusion, but this image does not appear to be a grid of 36 images. The image you provided shows a single scene featuring a person standing in a gym with a set of dumbbells in the foreground and a mirror with a large crack in it in the background. The person is pointing at the cracked mirror, suggesting that they are discussing or reacting to it. Without further context, I can provide you with JSON-format information about just this one image:\\n\\n```json\\n{\\n  \"1\": \"Individual in a gym pointing at a cracked mirror, possibly addressing the damage.\"\\n}\\n```\\n\\nIf there is a grid of images you are referring to that is not visible here, please provide the appropriate visual or additional information.', role='assistant', function_call=None, tool_calls=None))], created=1712399067, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=1142, total_tokens=1292)),\n",
       " ChatCompletion(id='chatcmpl-9AxVthuOogBTFgWim3ILT76aOekgX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for any confusion, but it appears there has been a misunderstanding. The image you\\'ve provided is a single picture, and I only have the capability to analyze the content of this one image. There is no grid or set of 36 images present in your request. If you have multiple images you need information on, please provide them separately, and I can help analyze each.\\n\\nBased on the available image, here is the JSON format that describes its content:\\n\\n```json\\n{\\n  \"scene\": \"Home gym with exercise equipment\",\\n  \"primary_person\": \"Person standing and holding a phone\",\\n  \"clothing\": \"Person in red t-shirt and beige shorts\",\\n  \"equipment\": [\\n    \"Dumbbell rack with various weights\",\\n    \"Weight bench\",\\n    \"Medicine balls rack\",\\n    \"Resistance band station\",\\n    \"Barbell with weight plates\",\\n    \"Fireplace\"\\n  ]\\n}\\n```\\n\\nIf you need information in a different format or have more images to analyze, feel free to provide further instructions.', role='assistant', function_call=None, tool_calls=None))], created=1712399077, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=210, prompt_tokens=1142, total_tokens=1352)),\n",
       " ChatCompletion(id='chatcmpl-9AxW0UXIncuwyXeCVPUi0LQiyvD6T', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Apologies, but it appears there has been a misunderstanding. I am only able to see and analyze one image, which is a single logo on a red background. There is no \\'grid\\' of images visible here to dissect into 36 separate components as requested. However, I can describe the one image that is available:\\n\\n```json\\n{\\n  \"1\": \"The image features the logo of a well-known insurance company set against a solid red background.\"\\n}\\n```\\n\\nIf you have a grid of images or additional images you wish to analyze, please ensure that each one is visible and provided separately, and I\\'ll be happy to assist further.', role='assistant', function_call=None, tool_calls=None))], created=1712399084, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=130, prompt_tokens=1142, total_tokens=1272)),\n",
       " ChatCompletion(id='chatcmpl-9AxW69AGfjVuTbpx4elB98vlViWGQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sorry, I can't assist with that request.\", role='assistant', function_call=None, tool_calls=None))], created=1712399090, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=1142, total_tokens=1152)),\n",
       " ChatCompletion(id='chatcmpl-9AxW9AJMb0cS7MjHQkimVjTXHu01Y', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a misunderstanding. There is only one image provided here rather than a grid of 36 images. The current image shows a man standing in a parking garage. Here is the JSON format for the single image provided:\\n\\n```json\\n{\\n  \"image1\": \"man standing in a parking garage\"\\n}\\n```\\n\\nIf you have a grid of 36 images you want described, kindly provide all of them, and I will help you with the descriptions.', role='assistant', function_call=None, tool_calls=None))], created=1712399093, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=99, prompt_tokens=1142, total_tokens=1241)),\n",
       " ChatCompletion(id='chatcmpl-9AxWD6S9JgjblxhFlpLCDGqeThdlb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for the confusion, but there is only one image provided here and not a grid of 36 images. I can certainly describe the single image you\\'ve posted in JSON format. Here is the description of the image:\\n\\n```json\\n{\\n  \"description\": \"Two individuals having a conversation in an underground parking lot next to a parked car. There are overhead lights, and the ambiance suggests it could be a commercial or an advertisement as indicated by the text \\'State Farm • Bloomington, IL\\' at the bottom of the image. One individual is wearing a red jacket, and the other is wearing a black leather jacket and glasses.\"\\n}\\n```\\n\\nIf you were actually looking for analysis of a grid of 36 images, please provide that grid or clarify your request.', role='assistant', function_call=None, tool_calls=None))], created=1712399097, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=156, prompt_tokens=1142, total_tokens=1298)),\n",
       " ChatCompletion(id='chatcmpl-9AxWJZVQOozHFCZPV8HLFHQF9X9UM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I cannot provide a JSON response for a grid of images because you have only provided one image. The image you've shared appears to show a scene with two people, presumed to be characters, in a parking garage, with one person in a flannel jacket having a conversation with another person wearing a suit.\\n\\nIf you meant to provide a grid with multiple images or have additional images you'd like to inquire about, please share them so I can assist you accordingly.\", role='assistant', function_call=None, tool_calls=None))], created=1712399103, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=97, prompt_tokens=1142, total_tokens=1239)),\n",
       " ChatCompletion(id='chatcmpl-9AxWQFl4HsqAmKrLvWHi1NuLYDkVy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to have been a misunderstanding. The image you have provided is a single image, and it does not contain a grid of multiple images. The image displays logos of the NBA (National Basketball Association) and State Farm, an insurance company, along with the State Farm slogan, \"Like a good neighbor.\" If you have a specific grid of images you need to analyze, please provide that grid or describe how you\\'d like me to assist with this one image. \\n\\nFor this image:\\n\\n```json\\n{\\n  \"1\": \"NBA logo\",\\n  \"2\": \"State Farm logo\",\\n  \"3\": \"State Farm slogan \\'Like a good neighbor\\'\"\\n}\\n```\\n\\nPlease provide the correct grid or more details if you need assistance with multiple images.', role='assistant', function_call=None, tool_calls=None))], created=1712399110, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=158, prompt_tokens=1142, total_tokens=1300)),\n",
       " ChatCompletion(id='chatcmpl-9AxWaSlZwvszGsgmmshuUIFkPkkDn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a misunderstanding. The image you\\'ve provided appears to be a single image and not a grid of multiple images. Additionally, you\\'ve mentioned getting descriptions for 36 images; however, only one image is visible here. Based on this single image, I can provide a description in JSON format:\\n\\n```json\\n{\\n  \"image1\": \"A man in a red and white varsity jacket labeled \\'The New Chris Paul\\' is in a blurred indoor setting, possibly entering or exiting a room while another person with a black wig appears to be gesturing or speaking to him.\"\\n}\\n```\\n\\nIf you have a grid of images or additional images, please provide them, and I can give you descriptions for each of them accordingly.', role='assistant', function_call=None, tool_calls=None))], created=1712399120, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=154, prompt_tokens=1142, total_tokens=1296)),\n",
       " ChatCompletion(id='chatcmpl-9AxWhJkTlrtO7uzhtETVO1fdEs3Hq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for the confusion, but it seems there is only one image provided. I cannot generate a JSON response for 36 images based on this one image. Nonetheless, I can describe what this image is about in JSON format. Here is the description of the provided image:\\n\\n```json\\n{\\n  \"image_description\": \"A scene from a school pep rally inside a gymnasium with students, cheerleaders, and a mascot present. Banners that read \\'Go Titans!\\' and \\'West Forsyth\\' are visible, suggesting a high school sporting event. There is confetti in the air and people are clapping, indicating a celebratory atmosphere.\"\\n}\\n```\\n\\nThis description is based on the elements visible within this singular image. If you meant to provide multiple images or a grid of images, I would need to see all the images to describe each one accordingly.', role='assistant', function_call=None, tool_calls=None))], created=1712399127, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=175, prompt_tokens=1142, total_tokens=1317)),\n",
       " ChatCompletion(id='chatcmpl-9AxWp4Czq2kYzEP6bmW3XoAPszHAL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sorry, I can't assist with that request.\", role='assistant', function_call=None, tool_calls=None))], created=1712399135, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=1142, total_tokens=1152)),\n",
       " ChatCompletion(id='chatcmpl-9AxWrjdFFcJ12K3m121HI4nEeMGMA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for any confusion, but the image you provided is just one image, not a grid of 36 images. From the single image, I can provide a description in JSON format:\\n\\n```json\\n{\\n  \"description\": \"A group of people at a party, with one man in a red sweater looking intently at another while conversing. There\\'s a person in a varsity jacket entering the room, and a girl in a plaid skirt smiling while talking. \\'WEST COAST TITANS\\' is written on one of the person\\'s shirt, suggesting a school or sports team, and there are golden balloons shaped as the number \\'38\\', indicating a celebration for a 38th event or anniversary.\"\\n}\\n```\\n\\nIf you meant to send multiple images or a grid to analyze, please provide the correct image or images, and I will gladly assist you with that.', role='assistant', function_call=None, tool_calls=None))], created=1712399137, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=179, prompt_tokens=1142, total_tokens=1321)),\n",
       " ChatCompletion(id='chatcmpl-9AxWzjOARc8PYLikYFrulhH5dhSNO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it seems there has been a misunderstanding. The image you provided is a single image and not a grid of multiple images. The image shows a red background with the logos of the National Basketball Association (NBA) and State Farm, an insurance company, indicating some sort of partnership or sponsorship deal.\\n\\nHere is a simplified JSON representation of the image content:\\n\\n```json\\n{\\n  \"image_details\": {\\n    \"background_color\": \"red\",\\n    \"logos_included\": [\\n      \"NBA logo\",\\n      \"State Farm logo\"\\n    ],\\n    \"indication\": \"Partnership or sponsorship between NBA and State Farm\"\\n  }\\n}\\n```\\n\\nPlease provide the full grid or correct the request if you were expecting information on multiple images.', role='assistant', function_call=None, tool_calls=None))], created=1712399145, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=155, prompt_tokens=1142, total_tokens=1297)),\n",
       " ChatCompletion(id='chatcmpl-9AxX6wzWVMbJWQZkxbRJ2oOVBLd4v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sorry, there seems to be a misunderstanding. I see only one image provided here and no grid with 36 images. The image you\\'ve provided features a person standing beside a car. He appears to be smiling and polishing or wiping the car with a cloth. Please provide the grid of images or clarify your request if you\\'d like me to analyze multiple images. For the single image provided, here\\'s a JSON representation:\\n\\n```json\\n{\\n  \"image_description\": \"A person standing beside a car, smiling, and appearing to polish or wipe the car with a cloth.\"\\n}\\n```', role='assistant', function_call=None, tool_calls=None))], created=1712399152, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=117, prompt_tokens=1142, total_tokens=1259)),\n",
       " ChatCompletion(id='chatcmpl-9AxXBHcMBAnBy7ZHIQ4nR74mcshPo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sorry, but it seems there was a misunderstanding. The image provided is a single image and not a grid containing 36 images. I can, however, describe the image provided:\\n\\n```json\\n{\\n  \"description\": \"A man in a red and white jacket is smiling and playing basketball with a young boy who has his back to the camera. They seem to be in a residential area with houses and plants in the background.\"\\n}\\n```\\n\\nIf you have a grid of 36 images, please provide it, and then I can help describe each one in JSON format as requested.', role='assistant', function_call=None, tool_calls=None))], created=1712399157, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=117, prompt_tokens=1142, total_tokens=1259)),\n",
       " ChatCompletion(id='chatcmpl-9AxXJqifp0spq2bT1Ke5tuW1iq5Od', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a misunderstanding. The image provided is a single image and does not depict a grid with multiple images. Therefore, I can\\'t provide a JSON format response for 36 images from this input. However, I can give you a summary of the provided image in a JSON format. Here it is:\\n\\n```json\\n{\\n  \"image_description\": \"A person leaning on a car in front of a house\"\\n}\\n```\\n\\nIf you have an actual grid of images you would like analyzed, please provide the appropriate image, and I\\'ll do my best to assist you.', role='assistant', function_call=None, tool_calls=None))], created=1712399165, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=122, prompt_tokens=1142, total_tokens=1264)),\n",
       " ChatCompletion(id='chatcmpl-9AxXRvi1imJddPdsEgS8XA7c2Sm1t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but there seems to be a misunderstanding. The image provided is a single image and not a grid of images. The image depicts two men standing in front of a house, with one leaning on a car. There is text superimposed on the image indicating that it is likely related to an advertisement for State Farm Mutual Automobile Insurance Company, as well as a mock license plate that reads \"1BCHRIS\" suggesting a personalized touch, possibly indicating it’s a creative element for the advertisement. Here is a JSON representation of the content of the image:\\n\\n```json\\n{\\n  \"image_content\": \"Two men standing outside a house with one leaning on a car, possibly in an advertisement for State Farm Automobile Insurance.\"\\n}\\n```\\n\\nIf you are looking for a grid of images or require additional images to be analyzed, please provide the correct images or further instructions.', role='assistant', function_call=None, tool_calls=None))], created=1712399173, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=176, prompt_tokens=1142, total_tokens=1318)),\n",
       " ChatCompletion(id='chatcmpl-9AxXcWADGOEafBD2uURHdOWnOgwLG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry, but it appears that there is only one image visible here – a red background with three white dots forming a diagonal line in the center. There is no grid of images to provide 36 different descriptions for. Here is the JSON format for the description of the given image:\\n\\n```json\\n{\\n  \"image_description\": \"A red background with three white dots forming a diagonal line in the center.\"\\n}\\n```\\n\\nIf you have a grid of images elsewhere that you would like to be described, please provide them so that I can assist you further.', role='assistant', function_call=None, tool_calls=None))], created=1712399184, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=113, prompt_tokens=1142, total_tokens=1255)),\n",
       " ChatCompletion(id='chatcmpl-9AxXnSkYr1U7xJEzeZeQ0P46j5uSd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m sorry for the confusion, but it seems there has been a misunderstanding. The image you provided appears to be a single image rather than a grid of multiple images. The image shows a man on the phone, appearing to have a conversation. He seems to have a concerned or bothered expression on his face, and he\\'s holding his chest, which might indicate he\\'s emotionally affected by the conversation. The setting looks like a residential interior, possibly a home.\\n\\nHere is an example of how the information could be represented in JSON format for this one image:\\n\\n```json\\n{\\n  \"image_1\": \"A man on the phone with a concerned expression, holding his chest, indoors, likely at home.\"\\n}\\n```\\n\\nIf you have a grid of images, you would need to provide the grid or describe it for further assistance. Please provide more details or the actual grid for me to continue with the request.', role='assistant', function_call=None, tool_calls=None))], created=1712399195, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=183, prompt_tokens=1142, total_tokens=1325))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jwt =\"eyJpZGVudGl0aWVzIjp7ImNhbnZhcyI6eyJ1c2VyX2lkIjoiMTMxNTQwMDAwMDAwMTAzOTk0IiwiY3JlYXRlZCI6IjIwMjQtMDQtMDZUMjA6MDQ6MzguNDk3WiJ9fX0=\"\n",
    "token ='13154~eo2OlaeC8EJ7R4spMPdGsn21y8Nu3BBsvelzpVOfl350CzRc6F8DSzGbojuFNIzt'\n",
    "course_id = 34349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace these values with your actual credentials and course ID\n",
    "ACCESS_TOKEN = token\n",
    "COURSE_ID = course_id\n",
    "\n",
    "# Base URL for Canvas API\n",
    "BASE_URL = \"https://morganstate.instructure.com/api/v1\"\n",
    "\n",
    "# Construct the URL to retrieve files associated with the course\n",
    "files_url = f\"{BASE_URL}/courses/{COURSE_ID}/files\"\n",
    "\n",
    "# Make a GET request to retrieve files\n",
    "response = requests.get(files_url, headers={\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [401]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if request was successful\n",
    "if response.status_code == 200:\n",
    "    files_data = response.json()\n",
    "    for file_data in files_data:\n",
    "        if file_data[\"content-type\"] == \"application/pdf\":\n",
    "            file_id = file_data[\"id\"]\n",
    "            file_name = file_data[\"filename\"]\n",
    "            # Construct the URL to download the file\n",
    "            file_download_url = f\"{BASE_URL}/files/{file_id}\"\n",
    "            # Make a GET request to download the file\n",
    "            file_response = requests.get(file_download_url, headers={\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"})\n",
    "            # Check if request was successful\n",
    "            if file_response.status_code == 200:\n",
    "                # Save the file to disk\n",
    "                with open(file_name, \"wb\") as file:\n",
    "                    file.write(file_response.content)\n",
    "                    print(f\"Downloaded {file_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to download file {file_name}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve files from the course\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
